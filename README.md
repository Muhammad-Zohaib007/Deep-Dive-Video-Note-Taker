# ğŸš€ Deep-Dive Video Note Taker
`LLM + RAG`
<div align="center">

<h3>ğŸ¥ Local Video â†’ Structured Notes + Timestamps + Action Items + RAG Q&A</h3>

<p>
<strong>CPU-only â€¢ Privacy-First â€¢ Offline-Capable â€¢ LLM Powered</strong>
</p>

<p>
<img src="https://img.shields.io/badge/python-3.10%2B-blue" />
<img src="https://img.shields.io/badge/license-MIT-green" />
<img src="https://img.shields.io/badge/LLM-Ollama-orange" />
<img src="https://img.shields.io/badge/RAG-ChromaDB-purple" />
<img src="https://img.shields.io/badge/STT-whisper.cpp-red" />
</p>

<p><em>Convert long YouTube videos, lectures, and meetings into structured knowledge â€” locally.</em></p>

</div>

---

<hr>

## ğŸ” What Is This?

**Deep-Dive Video Note Taker (Lite)** is a local AI system that converts long videos into:

<ul>
<li>ğŸ“Œ Structured notes</li>
<li>â±ï¸ Key timestamps</li>
<li>âœ… Action items</li>
<li>ğŸ§  RAG-based Q&A with citations</li>
</ul>

No cloud upload required. Everything runs locally using:

* whisper.cpp
* sentence-transformers
* ChromaDB
* Ollama (LLM)

---

## ğŸ§  Architecture Overview

```mermaid
flowchart LR
    A[Video Input] --> B[Audio Extraction]
    B --> C[Speech-to-Text]
    C --> D[Chunk + Embed]
    D --> E[Vector DB]
    E --> F[LLM Notes Generator]
    E --> G[RAG Q&A]
```

---

## âœ¨ Core Features

<div style="background:#f6f8fa;padding:15px;border-radius:8px">

### ğŸ¥ Input

* YouTube URL
* Local video file
* Batch processing

### ğŸ“ Output

* Structured summary
* Multi-level notes
* Timestamped highlights
* Action item extraction
* Export to Markdown / JSON / Obsidian / Notion

### ğŸ§  Intelligence Layer

* Semantic chunking
* Embedding-based retrieval
* RAG pipeline
* Citation-backed answers

</div>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Install Dependencies

```bash
pip install poetry
poetry install
```

### 2ï¸âƒ£ Install Ollama Model

```bash
ollama pull llama3.1:8b
```

### 3ï¸âƒ£ Process a Video

```bash
poetry run notetaker process "https://www.youtube.com/watch?v=VIDEO_ID"
```

### 4ï¸âƒ£ Ask Questions (RAG)

```bash
poetry run notetaker query VIDEO_ID "What were the main insights?"
```

---

## ğŸŒ Web UI + REST API

Start server:

```bash
poetry run notetaker serve
```

Open:

* Web UI â†’ [http://localhost:8000](http://localhost:8000)
* Health â†’ [http://localhost:8000/health](http://localhost:8000/health)

### API Endpoints

```http
POST   /api/process
POST   /api/process/upload
GET    /api/status/{job_id}
GET    /api/notes/{video_id}
GET    /api/transcript/{video_id}
POST   /api/query/{video_id}
GET    /api/library
GET    /api/export/{video_id}?format=json|markdown|obsidian|notion
DELETE /api/video/{video_id}
```

---

## ğŸ“¦ Tech Stack

<div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:10px">

<div style="background:#f0f0f0;padding:10px;border-radius:6px">
<strong>Speech-to-Text</strong><br>
whisper.cpp
</div>

<div style="background:#f0f0f0;padding:10px;border-radius:6px">
<strong>Embeddings</strong><br>
sentence-transformers
</div>

<div style="background:#f0f0f0;padding:10px;border-radius:6px">
<strong>Vector DB</strong><br>
ChromaDB
</div>

<div style="background:#f0f0f0;padding:10px;border-radius:6px">
<strong>LLM</strong><br>
Ollama (llama3.1:8b)
</div>

</div>

---

## âš™ï¸ Configuration

User config:

```
~/.notetaker/config.yaml
```

Environment variables:

```
NOTETAKER_OLLAMA_BASE_URL
NOTETAKER_OLLAMA_MODEL
NOTETAKER_WHISPER_MODEL
NOTETAKER_DATA_DIR
NOTETAKER_NOTION_API_KEY
```

---

## ğŸ“¤ Exports

* JSON
* Markdown
* Obsidian (YAML + callouts)
* Notion blocks JSON

---

## ğŸ³ Docker

```bash
docker compose up --build
```

App â†’ [http://localhost:8000](http://localhost:8000)
Ollama â†’ [http://localhost:11434](http://localhost:11434)

---

## â“ FAQ 

### Does it upload my videos?

No. Everything runs locally.

### Can I use it offline?

Yes â€” fully offline if Ollama + models are installed.

### Can I search my entire video library?

Yes â€” semantic retrieval via ChromaDB.

### Example Queries

* â€œSummarize the lecture in 5 bullet pointsâ€
* â€œList action items from 00:20â€“00:40â€
* â€œWhere was regression discussed?â€

---

## ğŸ§ª Development

Run tests:

```bash
poetry run pytest -v
```

Lint:

```bash
poetry run ruff check .
```

---

## ğŸ¤ Contributing

PRs welcome.

1. Fork
2. Create branch
3. Add tests
4. Open PR

---

## ğŸ“„ License

MIT
