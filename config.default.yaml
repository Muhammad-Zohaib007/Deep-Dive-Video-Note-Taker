# Deep-Dive Video Note Taker - Default Configuration
# Copy to ~/.notetaker/config.yaml to customize

# General settings
data_dir: "~/.notetaker"
output_dir: "./outputs"

# Video constraints
max_video_duration_seconds: 900  # 15 minutes

# Stage 1: Audio extraction
audio:
  sample_rate: 16000
  channels: 1  # mono
  format: "wav"

# Stage 2: Transcription (whisper.cpp)
whisper:
  model: "small"  # tiny | base | small | medium
  language: "en"

# Stage 3: Embedding
embedding:
  model: "all-MiniLM-L6-v2"
  chunk_size_tokens: 250
  chunk_overlap_tokens: 50
  dimensions: 384

# Stage 4: LLM generation (Ollama)
ollama:
  base_url: "http://localhost:11434"
  model: "llama3.1:8b"
  temperature: 0.3
  max_tokens: 2048
  timeout_seconds: 900  # 15 min â€” CPU inference is slow

# Stage 5: RAG Q&A
rag:
  top_k: 5
  similarity_threshold: 0.3

# ChromaDB
chroma:
  persist_directory: "~/.notetaker/chroma"
  collection_name: "notetaker_default"

# API server
api:
  host: "0.0.0.0"
  port: 8000

# Logging
logging:
  level: "INFO"
  log_dir: "~/.notetaker/logs"
  max_bytes: 10485760
  backup_count: 5

# Caching
cache:
  enabled: true
  transcript_cache: true
  llm_output_cache: true
